{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c7169756adcbe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c966d5cd28de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47adf37081d73c21",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Observability & Monitoring\n",
    "\n",
    "Phoenix is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows AI Engineers and Data Scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0092013e36ca8c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "import phoenix as px\n",
    "\n",
    "px.close_app()\n",
    "session = px.launch_app()\n",
    "\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd676a30f7effbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f2033ded77748",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028a391597bb1de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Cleantech Media Dataset/cleantech_media_dataset_v2_2024-02-23.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75b6e2aa712181",
   "metadata": {},
   "source": [
    "# Preprocessing & Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb436cf3c7906ac5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Splitting content into paragraphs\n",
    "\n",
    "The content is currently stored as a list of strings. We will convert this into a single string with paragraphs separated by two newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d6b974dc56bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['content'] = df['content'].apply(ast.literal_eval)\n",
    "df['content'] = df['content'].apply(lambda x: [str(i) for i in x])\n",
    "df['content'] = df['content'].apply(lambda x: '\\n\\n'.join(x))\n",
    "df['content'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f172af1ea76470",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Indexing\n",
    "\n",
    "For the indexing we use the VectorStore class which bundles the embeddings and ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a4a16684d3b86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.vectorstore import VectorStore\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en\", \n",
    "    model_kwargs={\"device\": \"cpu\"}, \n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184c2f957d3c60d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=32, length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066402773ac9d58",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_documents(df, splitter):\n",
    "    docs = []\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        content = row['content']\n",
    "\n",
    "        row = row.fillna('')\n",
    "\n",
    "        metadata = {\n",
    "            \"url\": row['url'],\n",
    "            \"domain\": row['domain'],\n",
    "            \"title\": row['title'],\n",
    "            \"author\": row['author'],\n",
    "            \"date\": row['date']\n",
    "        }\n",
    "        \n",
    "        for chunk in splitter.split_text(content):\n",
    "            docs.append(Document(page_content=chunk, metadata=metadata))\n",
    "    \n",
    "    return docs\n",
    "\n",
    "documents = create_documents(df, recursive_text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ace88dd27a69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"ChromeDB Host: \", os.getenv('CHROMADB_HOST'))\n",
    "print(\"ChromeDB Port: \", os.getenv('CHROMADB_PORT'))\n",
    "\n",
    "bge_vector_store = VectorStore(embedding_function=bge_embeddings,\n",
    "                               collection=\"cleantech-bge-small-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20213c70591f14",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the next step we will add the documents to the vector store. This will take a while depending on the number of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d558939648a829",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "bge_vector_store.add_documents(documents, verbose=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2177cd39686a8db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After adding the documents to the vector store we can now perform similarity searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a13de926826f7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bge_vector_store.similarity_search_w_scores(\"The company is also aiming to reduce gas flaring?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad87a39c366b0b3",
   "metadata": {},
   "source": [
    "# Retrieval & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9b043d8d6a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation import get_llm_model, LLMModel\n",
    "\n",
    "azure_model = get_llm_model(LLMModel.GPT_3_AZURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6ebdf4dab2924",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rag_prompt = \"\"\"\n",
    "Answer the question to your best knowledge when looking at the following context:\n",
    "{context}\n",
    "                \n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfe841ed24a7a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "        | ChatPromptTemplate.from_template(rag_prompt)\n",
    "        | azure_model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\n",
    "        \"context\": bge_vector_store.get_retriever(), \n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1225784152974",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rag_chain_with_source.invoke(\"Is the company aiming to reduce gas flaring?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c9f4f51cdcb2f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc9616ebdc0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv('data/Cleantech Media Dataset/cleantech_rag_evaluation_data_2024-02-23.csv')\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_eval_subset = pd.read_csv('data/Cleantech Media Dataset/cleantech_media_dataset_v2_2024-02-23_subset_eval.csv')\n",
    "df_eval_subset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad1d73f0cad6c2a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove nan values\n",
    "df_eval_subset = df_eval_subset.dropna(subset=['answer'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d03b830d54205118",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.evaluation import RAGEvaluator\n",
    "\n",
    "rag_evaluator = RAGEvaluator(chain=rag_chain_with_source,\n",
    "                             llm_model=azure_model,\n",
    "                             embeddings=bge_embeddings)\n",
    "\n",
    "rag_evaluator.create_dataset_from_df(df_eval_subset)\n",
    "rag_evaluator.evaluate(raise_exceptions=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5bccbe256adad5d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
