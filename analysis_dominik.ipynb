{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "629c7169756adcbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c966d5cd28de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observability & Monitoring\n",
    "\n",
    "Phoenix is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows AI Engineers and Data Scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47adf37081d73c21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "import phoenix as px\n",
    "\n",
    "px.close_app()\n",
    "session = px.launch_app()\n",
    "\n",
    "LangChainInstrumentor().instrument()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d0092013e36ca8c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "session.view()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd676a30f7effbe",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f9f2033ded77748"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "        \n",
    "df = pd.read_csv('data/Cleantech Media Dataset/cleantech_media_dataset_v2_2024-02-23_subset.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a41645ff9ed1f954",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e75b6e2aa712181",
   "metadata": {},
   "source": [
    "# Preprocessing & Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting content into paragraphs\n",
    "\n",
    "The content is currently stored as a list of strings. We will keep this structure and explode the list into separate rows, based on the content."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb436cf3c7906ac5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27844259f6d23087"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbb4386a08ad35d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.preprocessing.preprocessor import Preprocessor\n",
    "\n",
    "preprocesser = Preprocessor(df)\n",
    "df = preprocesser.preprocess()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42723d3f2a3835c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a6e43078b2837e9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ef106f1fec67b26",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Indexing\n",
    "\n",
    "For the indexing we use the VectorStore class which bundles the embeddings and ChromaDB."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29f172af1ea76470"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.vectorstore import VectorStore\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en\", \n",
    "    model_kwargs={\"device\": \"cpu\"}, \n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0a4a16684d3b86",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_documents(df):\n",
    "    docs = []\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        content = row['content']\n",
    "\n",
    "        row = row.fillna('')\n",
    "\n",
    "        metadata = {\n",
    "            \"url\": row['url'],\n",
    "            \"domain\": row['domain'],\n",
    "            \"title\": row['title'],\n",
    "            \"author\": row['author'],\n",
    "            \"date\": row['date']\n",
    "        }\n",
    "        \n",
    "        docs.append(Document(page_content=content, metadata=metadata))\n",
    "    \n",
    "    return docs\n",
    "\n",
    "documents = create_documents(df)\n",
    "\n",
    "assert len(documents) == len(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f066402773ac9d58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"ChromeDB Host: \", os.getenv('CHROMADB_HOST'))\n",
    "print(\"ChromeDB Port: \", os.getenv('CHROMADB_PORT'))\n",
    "\n",
    "\n",
    "bge_vector_store = VectorStore(embedding_function=bge_embeddings,\n",
    "                               collection=\"cleantech-subset-analysis-1\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f738ace88dd27a69",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next step we will add the documents to the vector store. This will take a while depending on the number of documents."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f20213c70591f14"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "bge_vector_store.add_documents(documents, verbose=True, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "181b398da2243d1b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "After adding the documents to the vector store we can now perform similarity searches."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2177cd39686a8db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# bge_vector_store.similarity_search_w_scores(\"The company is also aiming to reduce gas flaring?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91a13de926826f7f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7ad87a39c366b0b3",
   "metadata": {},
   "source": [
    "# Retrieval & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Retrieval Cooking \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7cab945fee79d04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9b043d8d6a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation import get_llm_model, LLMModel\n",
    "\n",
    "azure_model = get_llm_model(LLMModel.GPT_3_AZURE)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_prompt = \"\"\"\n",
    "Answer the question to your best knowledge when looking at the following context:\n",
    "{context}\n",
    "                \n",
    "Question: {question}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc6ebdf4dab2924",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "        | ChatPromptTemplate.from_template(rag_prompt)\n",
    "        | azure_model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\n",
    "        \"context\": bge_vector_store.get_retriever(), \n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ").assign(answer=rag_chain_from_docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83dfe841ed24a7a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_chain_with_source.invoke(\"Is the company aiming to reduce gas flaring?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b1225784152974",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of first retrieval cooking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e28038518af5702"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_eval_subset = pd.read_csv('data/Cleantech Media Dataset/cleantech_media_dataset_v2_2024-02-23_subset_eval.csv')\n",
    "df_eval_subset = df_eval_subset[:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eddfb4f5f174e5f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove nan values\n",
    "df_eval_subset = df_eval_subset.dropna(subset=['answer'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc87d24c21ccce1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_eval_subset.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e34a577248dc2a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.evaluation import RAGEvaluator\n",
    "\n",
    "rag_evaluator = RAGEvaluator(chain=rag_chain_with_source,\n",
    "                             llm_model=azure_model,\n",
    "                             embeddings=bge_embeddings)\n",
    "\n",
    "rag_evaluator.create_dataset_from_df(df_eval_subset)\n",
    "rag_evaluator.evaluate(raise_exceptions=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0b27f79212d488",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alternative Retrieval Cooking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1380dfe56dc22522"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_prompt = \"\"\"\n",
    "Answer the question to your best knowledge when looking at the following context:\n",
    "{context}\n",
    "                \n",
    "Question: {question}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f03ae232b3f4e6e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_gpt_improved_prompt = \"\"\"\n",
    "\n",
    "Critically answer the question, using the following context and your own knowledge:\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "In case that the provided context is not sufficient, explain that the knowledge is not available but that given your own knowledge you can provide an answer which you will tag as (own knowledge).\n",
    "\n",
    "Ensure that the answer is well-structured and provides a clear and concise response.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2923b6c4aae3cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "        | ChatPromptTemplate.from_template(rag_gpt_improved_prompt)\n",
    "        | azure_model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\n",
    "        \"context\": bge_vector_store.get_retriever(), \n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ").assign(answer=rag_chain_from_docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10dd6f1991100a91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_chain_from_docs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "306ed83b1b8fd426",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_chain_with_source.invoke(\"Is the company aiming to reduce gas flaring?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0e382b76c63b232",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9a0c9f4f51cdcb2f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv('data/Cleantech Media Dataset/cleantech_rag_evaluation_data_2024-02-23.csv')\n",
    "df_eval.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a644472a8b5afd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_eval_subset = pd.read_csv('data/Cleantech Media Dataset/cleantech_media_dataset_v2_2024-02-23_subset_eval.csv')\n",
    "df_eval_subset = df_eval_subset[:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d51e57fb07ef5ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove nan values\n",
    "df_eval_subset = df_eval_subset.dropna(subset=['answer'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5658369036e915a6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.evaluation import RAGEvaluator\n",
    "\n",
    "rag_evaluator = RAGEvaluator(chain=rag_chain_with_source,\n",
    "                             llm_model=azure_model,\n",
    "                             embeddings=bge_embeddings)\n",
    "\n",
    "rag_evaluator.create_dataset_from_df(df_eval_subset)\n",
    "rag_evaluator.evaluate(raise_exceptions=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea2d69af01143b3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further try evaluating the model with Phoenix's evaluation tools. Read more: https://docs.arize.com/phoenix/evaluation/running-pre-tested-evals/retrieval-rag-relevance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbb98ddc172dd8bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
