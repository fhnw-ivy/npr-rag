{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from html import unescape\n",
    "import re\n",
    "\n",
    "RANDOM_SEED = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f75c0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5647b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "documents = pd.read_csv('data/Cleantech Media Dataset/cleantech_media_dataset_v2_2024-02-23.csv')\n",
    "\n",
    "documents.sample(5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "documents['content'] = documents['content'].apply(ast.literal_eval)\n",
    "\n",
    "documents = documents.explode('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a2a40",
   "metadata": {},
   "source": [
    "### Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0779b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set everything to lowercase\n",
    "documents['content'] = documents['content'].str.lower()\n",
    "\n",
    "# remove stopwords from content\n",
    "stop_words = set(stopwords.words('english'))\n",
    "documents['content'] = documents['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# remove quotes\n",
    "documents['content'] = documents['content'].str.replace(\"'\", '')\n",
    "\n",
    "# unescape HTML entities\n",
    "documents['content'] = unescape(documents['content'])\n",
    "\n",
    "# remove HTML tags if any\n",
    "documents['content'] = documents['content'].str.replace(r'<[^>]+>', '')\n",
    "\n",
    "# Removes specific unwanted characters\n",
    "documents['content'] = documents['content'].str.replace(r\"[\\'\\/`:“`’]+\", '', regex=True)\n",
    "\n",
    "# Removes non-ASCII (Unicode) characters\n",
    "documents['content'] = documents['content'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    "# Keeps only letters and whitespace\n",
    "documents['content'] = documents['content'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "\n",
    "# trim extra spaces\n",
    "documents['content'] = documents['content'].str.strip()\n",
    "\n",
    "documents.sample(5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db7c8bb4c7128f",
   "metadata": {},
   "source": [
    "## CSV - Embedding - Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c643c25e8fc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in evaluation\n",
    "evaluation_set = pd.read_csv('./data/Cleantech Media Dataset/cleantech_rag_evaluation_data_2024-02-23.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd198e03ffec5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "\n",
    "text_splitter = SemanticChunker(embeddings)\n",
    "\n",
    "docs = []\n",
    "\n",
    "# create batches\n",
    "BatchSize = 41666\n",
    "batches = [documents[i:i + BatchSize] for i in range(0, len(documents), BatchSize)]\n",
    "\n",
    "for batch in batches:\n",
    "    docs.extend(text_splitter.create_documents(batch.content, metadatas=[\n",
    "        {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"date\": date,\n",
    "            \"author\": author,\n",
    "            \"domain\": domain,\n",
    "        }\n",
    "        for url, title, date, author, domain in zip(batch.url, batch.title, batch.date, batch.author, batch.domain)\n",
    "    ]))\n",
    "\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05769f33e5a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff56ddafdbfc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader \n",
    "\n",
    "# this is useless\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# dataframe from list \n",
    "\n",
    "\n",
    "loader = DataFrameLoader(chunked_documents, page_content_column='content')\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97846c14d184275",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "chroma_client.reset()\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=\"my_langchain_collection\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# create batches\n",
    "BatchSize = 41666\n",
    "batches = [chunked_documents[i:i + BatchSize] for i in range(0, len(chunked_documents), BatchSize)]\n",
    "\n",
    "for batch in batches:\n",
    "    langchain_chroma.add_documents(documents=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77921a2093b82f8c",
   "metadata": {},
   "source": [
    "## Similarity Search\n",
    "Query against the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33982f5f51eacc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the rag evaluation set\n",
    "print(evaluation_set.iloc[0].question)\n",
    "docs = langchain_chroma.similarity_search(evaluation_set.iloc[0].question)\n",
    "print(docs[0].page_content)\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdba57757d9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison with the intended RAG context \n",
    "\n",
    "evaluation_set.iloc[0].relevant_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008e32acdc26cae",
   "metadata": {},
   "source": [
    "## similarity_search_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b89451466a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_score = langchain_chroma.similarity_search_with_score(evaluation_set.iloc[0].question)\n",
    "print(docs_score[0][0].page_content)\n",
    "print(docs_score[0][0].metadata)\n",
    "print(\"Score: \", docs_score[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d963ff8f07d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set.iloc[0].relevant_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a881028b3cafe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "score = 0\n",
    "fuzzy_score = 0\n",
    "\n",
    "# iterate through evaluation set\n",
    "for index, row in evaluation_set.iterrows():\n",
    "    similarity_search = langchain_chroma.similarity_search_with_score(row.question)[:3]\n",
    "    print(\"Question: \", row.question)\n",
    "    print(\"Relevant Chunk: \", row.relevant_chunk)\n",
    "    for i in range(3):\n",
    "        print(\"Result \", i, \": \", similarity_search[i][0].page_content)\n",
    "        print(\"Score \", i, \": \", similarity_search[i][1])\n",
    "    # define own similarity based on fuzzy matching\n",
    "    fuzzy_match = fuzz.token_set_ratio(row.relevant_chunk, similarity_search[0][0].page_content)\n",
    "    print(\"Fuzzy Match: \", fuzzy_match)\n",
    "    print(\"Article Url: \", row.article_url)\n",
    "    print(\"Content Url: \", similarity_search[0][0].metadata['url'])\n",
    "    fuzzy_match_url = fuzz.token_set_ratio(row.article_url, similarity_search[0][0].metadata['url'])\n",
    "    print(\"Fuzzy Match Url: \", fuzzy_match_url)\n",
    "    print(\"----\")\n",
    "    \n",
    "    score += similarity_search[0][1]\n",
    "    fuzzy_score += fuzzy_match\n",
    "    \n",
    "print(\"Average Score: \", score/len(evaluation_set))\n",
    "print(\"Average Fuzzy Score: \", fuzzy_score/(100*len(evaluation_set)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe75af9f92b037",
   "metadata": {},
   "source": [
    "## Collection Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76953cb521268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_collection = chroma_client.get_collection(\"my_langchain_collection\")\n",
    "\n",
    "langchain_collection.query(\n",
    "    query_embeddings=[i for i in range(768)],\n",
    "    n_results=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e713739862062",
   "metadata": {},
   "source": [
    "## SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3608d24e92081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "# Metadata schema based on the values on the CSV\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"url\",\n",
    "        description=\"Url of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Title of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"Date of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author\",\n",
    "        description=\"Author of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"domain\",\n",
    "        description=\"Domain of the document, closely related to the source of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Article listing\"\n",
    "\n",
    "# Configure retriver\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, langchain_chroma, document_content_description, metadata_field_info, verbose=True\n",
    ")\n",
    "\n",
    "# Based on rag evaluation set \n",
    "result = retriever.get_relevant_documents(evaluation_set.iloc[0].question)\n",
    "print(result[0].page_content)\n",
    "print(result[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd901cc404608b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
